---
layout: blog
title: Writings
permalink: /writings/
---

In my experience, there's (generally) been surprisingly little expository content that's at the undergraduate level or above available on the internet. I think this is a bit of a shame, because reading expository books and articles was one of the things that got me really excited about maths and physics as a high school student. Some of my posts are thus aimed at filling this gap. On the other hand, some are just me rambling about things I think are interesting, and other posts are aimed at a more technical audience. 

Any opinions in these posts represent my own views at the time of writing, not my employers or affiliations. I may no longer agree with what I have written, and I'll try to note this at the top of articles when I realise my views have changed. 

# Effective Altruism and Rationality
I'm involved in the Effective Altruism, Rationality and AI Safety communities. Here are some of my writings on the [Effective Altruism Forum](https://forum.effectivealtruism.org/), [LessWrong](https://www.lesswrong.com/) and the [Alignment Forum](https://www.alignmentforum.org/): 

- **Estimating training compute of Deep Learning models** (20 Jan 2022) [[LW](https://www.lesswrong.com/posts/HvqQm6o8KnwxbdmhZ/estimating-training-compute-of-deep-learning-models), [AF](https://www.alignmentforum.org/posts/HvqQm6o8KnwxbdmhZ/estimating-training-compute-of-deep-learning-models)]  
*Co-authored by Lennart Heim, Jaime Sevilla, Marius Hobbhahn, and Tamay Besiroglu*
> As of January 2022, there isn't a very well established norm of publishing compute statistics for training machine learning models. To try and improve things, we offer some guidelines on how to estimate the compute of the final training run of ML systems, either through (1) direct calculation, or (2) approximations from GPU time.
- **Nines of safety: Terence Tao's proposed unit of measurement of risk** (11 Dec 2021) [[EA](https://forum.effectivealtruism.org/posts/L9pB9sWTngF4BcHeL/nines-of-safety-terence-tao-s-proposed-unit-of-measurement)]
> In his blog, Terence Tao proposed a measure of risk that is best suited to problems with low risk of a very bad outcome. Given that Effective Altruism deals with this stuff a lot, I wanted to hear some thoughts...
- **What role should evolutionary analogies play in understanding AI takeoff speeds?** (10 Dec 2021) [[EA](https://forum.effectivealtruism.org/posts/aSDnzAm85a3Pi87rm/what-role-should-evolutionary-analogies-play-in), [LW](https://www.lesswrong.com/posts/teD4xjwoeWc4LyRAD/what-role-should-evolutionary-analogies-play-in)]
> Arguments about the speed of the transition between modern Deep Learning systems and "Transformative AI" often depend on evolutionary analogies and disanalogies. But is this really valid? 

# Personal Notes
I sometimes also share my [personal notes](https://ansonwhho.github.io/personal-notes/) where I think they might be helpful. These are often quite rough and not very appropriate on a blog, so I keep them in a separate location. 

<br />

# Blog posts
I'm currently in the process of improving some of my older posts. Reader beware!

